1.     Main sources of Data Flood:

Top 10 Big Data source types are



·        Social network profiles

·        Social influence

·        Activity-generated data

·        Software as a Service (SaaS) and cloud applications

·         Public

·        Hadoop MapReduce application results

·        Data warehouse appliances

·        Columnar/NoSQL data sources

·        Network and in-stream monitoring technologies

·        Legacy Documents





2.     Difference Between Data and Big Data:

Data: Data is a set of values of qualitative or quantitative
variables. An example of qualitative data would be an anthropologist's
handwritten notes about her interviews with people of an Indigenous
tribe. Pieces of data are individual pieces of information. While the
concept of data is commonly associated with scientific research, data
is collected by a huge range of organizations and institutions,
including businesses (e.g., sales data, revenue, profits, and stock
price), governments (e.g., crime rates, unemployment rates, literacy
rates) and non-governmental organizations (e.g., censuses of the
number of homeless people by non-profit organizations).



Big Data:

Big data is a collection of data sets so large and complex that it
becomes difficult to process using on-hand database management tools.
The challenges include capture, curation, storage, search, sharing,
analysis, and visualization. The trend to larger data sets is due to
the additional information derivable from analysis of a single large
set of related data, as compared to separate smaller sets with the
same total amount of data, allowing correlations to be found to “spot
business trends, determine quality of research, prevent diseases, link
legal citations, combat crime, and determine real-time roadway traffic
conditions.

3.     What are main reasons behind Hadoop becoming the solution for
Data explosion:



The following are the main reasons of hadoop becoming the solution for
data exploding



·        Scalable: Hadoop is a highly scalable storage platform,
because it can store and distribute very large data sets across
hundreds of inexpensive servers that operate in parallel. Unlike
traditional relational database systems (RDBMS) that can't scale to
process large amounts of data, Hadoop enables businesses to run
applications on thousands of nodes involving thousands of terabytes of
data.



·        Cost effective: Hadoop also offers a cost effective storage
solution for businesses' exploding data sets. The problem with
traditional relational database management systems is that it is
extremely cost prohibitive to scale to such a degree in order to
process such massive volumes of data. In an effort to reduce costs,
many companies in the past would have had to down-sample data and
classify it based on certain assumptions as to which data was the most
valuable. The raw data would be deleted, as it would be too
cost-prohibitive to keep. While this approach may have worked in the
short term, this meant that when business priorities changed, the
complete raw data set was not available, as it was too expensive to
store. Hadoop, on the other hand, is designed as a scale-out
architecture that can affordably store all of a company's data for
later use. The cost savings are staggering: instead of costing
thousands to tens of thousands of pounds per terabyte, Hadoop offers
computing and storage capabilities for hundreds of pounds per
terabyte.





·        Flexible: Hadoop enables businesses to easily access new data
sources and tap into different types of data (both structured and
unstructured) to generate value from that data. This means businesses
can use Hadoop to derive valuable business insights from data sources
such as social media, email conversations or clickstream data. In
addition, Hadoop can be used for a wide variety of purposes, such as
log processing, recommendation systems, data warehousing, and market
campaign analysis and fraud detection.



·        Fast: Hadoop's unique storage method is based on a
distributed file system that basically 'maps' data wherever it is
located on a cluster. The tools for data processing are often on the
same servers where the data is located, resulting in much faster data
processing. If you're dealing with large volumes of unstructured data,
Hadoop is able to efficiently process terabytes of data in just
minutes, and petabytes in hours.





·        Resilient to failure: A key advantage of using Hadoop is its
fault tolerance. When data is sent to an individual node, that data is
also replicated to other nodes in the cluster, which means that in the
event of failure, there is another copy available for use.

The MapR distribution goes beyond that by eliminating the NameNode and
replacing it with a distributed No NameNode architecture that provides
true high availability. Our architecture provides protection from both
single and multiple failures.

When it comes to handling large data sets in a safe and cost-effective
manner, Hadoop has the advantage over relational database management
systems, and its value for any size business will continue to increase
as unstructured data continues to grow.
